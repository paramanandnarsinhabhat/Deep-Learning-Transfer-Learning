{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91734fc-fd74-4b22-b3ee-0a34fb11cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 10:56:25.066695: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-02-05 10:56:25.066717: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-02-05 10:56:25.066721: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-02-05 10:56:25.066997: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-05 10:56:25.067243: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 10:56:29.016404: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 22s 408ms/step\n",
      "23/23 [==============================] - 9s 412ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 10:57:01.902138: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 3s 46ms/step - loss: 0.6820 - accuracy: 0.5784 - val_loss: 0.6868 - val_accuracy: 0.5609\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6778 - accuracy: 0.5863 - val_loss: 0.6847 - val_accuracy: 0.5609\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6772 - accuracy: 0.5863 - val_loss: 0.6833 - val_accuracy: 0.5609\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.6758 - accuracy: 0.5863 - val_loss: 0.6838 - val_accuracy: 0.5609\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6753 - accuracy: 0.5863 - val_loss: 0.6842 - val_accuracy: 0.5609\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6733 - accuracy: 0.5863 - val_loss: 0.6837 - val_accuracy: 0.5609\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.6750 - accuracy: 0.5863 - val_loss: 0.6815 - val_accuracy: 0.5609\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6731 - accuracy: 0.5875 - val_loss: 0.6838 - val_accuracy: 0.5609\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6710 - accuracy: 0.5863 - val_loss: 0.6795 - val_accuracy: 0.5609\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6695 - accuracy: 0.5863 - val_loss: 0.6780 - val_accuracy: 0.5609\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6684 - accuracy: 0.5863 - val_loss: 0.6754 - val_accuracy: 0.5609\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6648 - accuracy: 0.5887 - val_loss: 0.6871 - val_accuracy: 0.5609\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6648 - accuracy: 0.5875 - val_loss: 0.6785 - val_accuracy: 0.5609\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6624 - accuracy: 0.5863 - val_loss: 0.6714 - val_accuracy: 0.5708\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.6596 - accuracy: 0.5881 - val_loss: 0.6711 - val_accuracy: 0.5609\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6573 - accuracy: 0.5936 - val_loss: 0.6673 - val_accuracy: 0.5637\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.6578 - accuracy: 0.6027 - val_loss: 0.6719 - val_accuracy: 0.5609\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6559 - accuracy: 0.6033 - val_loss: 0.6733 - val_accuracy: 0.5609\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6541 - accuracy: 0.5972 - val_loss: 0.6612 - val_accuracy: 0.5708\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.6504 - accuracy: 0.6045 - val_loss: 0.6589 - val_accuracy: 0.5666\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6487 - accuracy: 0.6087 - val_loss: 0.6568 - val_accuracy: 0.5779\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.6448 - accuracy: 0.6215 - val_loss: 0.6574 - val_accuracy: 0.5694\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6433 - accuracy: 0.6130 - val_loss: 0.6523 - val_accuracy: 0.5892\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6462 - accuracy: 0.6124 - val_loss: 0.6540 - val_accuracy: 0.5708\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6398 - accuracy: 0.6330 - val_loss: 0.6486 - val_accuracy: 0.5850\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 0.6336 - accuracy: 0.6191 - val_loss: 0.6462 - val_accuracy: 0.5963\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 0.6305 - accuracy: 0.6507 - val_loss: 0.6484 - val_accuracy: 0.6827\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.6293 - accuracy: 0.6416 - val_loss: 0.6422 - val_accuracy: 0.5992\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6275 - accuracy: 0.6440 - val_loss: 0.6385 - val_accuracy: 0.6487\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6340 - accuracy: 0.6428 - val_loss: 0.6368 - val_accuracy: 0.6331\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6223 - accuracy: 0.6434 - val_loss: 0.6364 - val_accuracy: 0.6119\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6181 - accuracy: 0.6488 - val_loss: 0.6337 - val_accuracy: 0.6232\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6164 - accuracy: 0.6464 - val_loss: 0.6363 - val_accuracy: 0.6756\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.6185 - accuracy: 0.6574 - val_loss: 0.6281 - val_accuracy: 0.6516\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.6113 - accuracy: 0.6756 - val_loss: 0.6300 - val_accuracy: 0.6176\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6088 - accuracy: 0.6731 - val_loss: 0.6474 - val_accuracy: 0.5751\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6089 - accuracy: 0.6610 - val_loss: 0.6218 - val_accuracy: 0.6657\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6057 - accuracy: 0.6646 - val_loss: 0.6221 - val_accuracy: 0.6459\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.6008 - accuracy: 0.6713 - val_loss: 0.6182 - val_accuracy: 0.6785\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.5989 - accuracy: 0.6859 - val_loss: 0.6220 - val_accuracy: 0.6360\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.5970 - accuracy: 0.6853 - val_loss: 0.6276 - val_accuracy: 0.6700\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5981 - accuracy: 0.6750 - val_loss: 0.6121 - val_accuracy: 0.6700\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.6025 - accuracy: 0.6701 - val_loss: 0.6199 - val_accuracy: 0.6346\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5914 - accuracy: 0.6883 - val_loss: 0.6089 - val_accuracy: 0.6813\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5948 - accuracy: 0.6768 - val_loss: 0.6104 - val_accuracy: 0.6530\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 0.5879 - accuracy: 0.6883 - val_loss: 0.6368 - val_accuracy: 0.5907\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5889 - accuracy: 0.6750 - val_loss: 0.6042 - val_accuracy: 0.6771\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5907 - accuracy: 0.6823 - val_loss: 0.6062 - val_accuracy: 0.6969\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5833 - accuracy: 0.6956 - val_loss: 0.6024 - val_accuracy: 0.6856\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5835 - accuracy: 0.6841 - val_loss: 0.5999 - val_accuracy: 0.6813\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.5795 - accuracy: 0.6926 - val_loss: 0.5991 - val_accuracy: 0.6827\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5784 - accuracy: 0.6968 - val_loss: 0.6004 - val_accuracy: 0.6700\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 0.5757 - accuracy: 0.6968 - val_loss: 0.5966 - val_accuracy: 0.6827\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 0.5788 - accuracy: 0.6999 - val_loss: 0.5962 - val_accuracy: 0.6856\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.5759 - accuracy: 0.7005 - val_loss: 0.5939 - val_accuracy: 0.6785\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 100s 2s/step - loss: 0.5812 - accuracy: 0.6956 - val_loss: 0.5936 - val_accuracy: 0.6856\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 0.5733 - accuracy: 0.6993 - val_loss: 0.5918 - val_accuracy: 0.6827\n",
      "Epoch 58/100\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 0.5694 - accuracy: 0.7047 - val_loss: 0.5902 - val_accuracy: 0.6827\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 0.5720 - accuracy: 0.6968 - val_loss: 0.5895 - val_accuracy: 0.6841\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5710 - accuracy: 0.6987 - val_loss: 0.5957 - val_accuracy: 0.6643\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5689 - accuracy: 0.7005 - val_loss: 0.5870 - val_accuracy: 0.6841\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5709 - accuracy: 0.7023 - val_loss: 0.5905 - val_accuracy: 0.6997\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5625 - accuracy: 0.6956 - val_loss: 0.6023 - val_accuracy: 0.6516\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 2s 42ms/step - loss: 0.5680 - accuracy: 0.6962 - val_loss: 0.5894 - val_accuracy: 0.6785\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5632 - accuracy: 0.6981 - val_loss: 0.5834 - val_accuracy: 0.6870\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5653 - accuracy: 0.6859 - val_loss: 0.6166 - val_accuracy: 0.6686\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5762 - accuracy: 0.6853 - val_loss: 0.5952 - val_accuracy: 0.6629\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5585 - accuracy: 0.7114 - val_loss: 0.5813 - val_accuracy: 0.6870\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5568 - accuracy: 0.7017 - val_loss: 0.5817 - val_accuracy: 0.6997\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5580 - accuracy: 0.7090 - val_loss: 0.5790 - val_accuracy: 0.6941\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5560 - accuracy: 0.7163 - val_loss: 0.5908 - val_accuracy: 0.6657\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5555 - accuracy: 0.7078 - val_loss: 0.5772 - val_accuracy: 0.6813\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5546 - accuracy: 0.7139 - val_loss: 0.5779 - val_accuracy: 0.6997\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5546 - accuracy: 0.7066 - val_loss: 0.5754 - val_accuracy: 0.6941\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5523 - accuracy: 0.7084 - val_loss: 0.5809 - val_accuracy: 0.6827\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 2s 38ms/step - loss: 0.5563 - accuracy: 0.7023 - val_loss: 0.6109 - val_accuracy: 0.6728\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5555 - accuracy: 0.7023 - val_loss: 0.5732 - val_accuracy: 0.6941\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.5512 - accuracy: 0.7029 - val_loss: 0.5809 - val_accuracy: 0.6799\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5497 - accuracy: 0.7090 - val_loss: 0.5810 - val_accuracy: 0.7082\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5513 - accuracy: 0.7181 - val_loss: 0.5730 - val_accuracy: 0.7040\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5475 - accuracy: 0.7126 - val_loss: 0.5705 - val_accuracy: 0.6983\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5498 - accuracy: 0.7078 - val_loss: 0.5713 - val_accuracy: 0.7025\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5475 - accuracy: 0.7139 - val_loss: 0.5695 - val_accuracy: 0.7011\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5427 - accuracy: 0.7199 - val_loss: 0.5701 - val_accuracy: 0.6955\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5481 - accuracy: 0.7169 - val_loss: 0.5960 - val_accuracy: 0.6586\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5497 - accuracy: 0.7151 - val_loss: 0.5980 - val_accuracy: 0.6558\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.5439 - accuracy: 0.7151 - val_loss: 0.5683 - val_accuracy: 0.6983\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5426 - accuracy: 0.7193 - val_loss: 0.5672 - val_accuracy: 0.6997\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5409 - accuracy: 0.7175 - val_loss: 0.5655 - val_accuracy: 0.7040\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5405 - accuracy: 0.7217 - val_loss: 0.5812 - val_accuracy: 0.6756\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5399 - accuracy: 0.7199 - val_loss: 0.5637 - val_accuracy: 0.7025\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5374 - accuracy: 0.7260 - val_loss: 0.5631 - val_accuracy: 0.6941\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5343 - accuracy: 0.7211 - val_loss: 0.5624 - val_accuracy: 0.7040\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5367 - accuracy: 0.7217 - val_loss: 0.5661 - val_accuracy: 0.6926\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5407 - accuracy: 0.7199 - val_loss: 0.5869 - val_accuracy: 0.6686\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5356 - accuracy: 0.7181 - val_loss: 0.5696 - val_accuracy: 0.6926\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.5431 - accuracy: 0.7151 - val_loss: 0.5673 - val_accuracy: 0.6926\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5364 - accuracy: 0.7230 - val_loss: 0.5611 - val_accuracy: 0.7040\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.5319 - accuracy: 0.7260 - val_loss: 0.5609 - val_accuracy: 0.7167\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.5309 - accuracy: 0.7211 - val_loss: 0.5587 - val_accuracy: 0.7011\n",
      "23/23 [==============================] - 0s 5ms/step\n",
      "Validation Accuracy: 70.11%\n"
     ]
    }
   ],
   "source": [
    "### 1. Importing Libraries and Data Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Flatten\n",
    "from keras.optimizers import Adam  # Using Adam optimizer\n",
    "\n",
    "### 2. Load and Preprocess the Data\n",
    "data = pd.read_csv('data/emergency_classification.csv')\n",
    "X = []\n",
    "for img_name in data.image_names:\n",
    "    img = plt.imread('data/images/' + img_name)\n",
    "    img = resize(img, (224, 224), anti_aliasing=True, mode='reflect')  # Resize images\n",
    "    X.append(img)\n",
    "X = np.array(X)\n",
    "X = preprocess_input(X)  # Preprocess the data\n",
    "y = to_categorical(data.emergency_or_not.values)\n",
    "\n",
    "### 3. Split the Dataset\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "### 4. Load the Pretrained VGG16 Model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.summary()  # Optional: to view model structure\n",
    "\n",
    "### 5. Fine-Tune the Model\n",
    "# Extract features\n",
    "X_train_features = base_model.predict(X_train)\n",
    "X_valid_features = base_model.predict(X_valid)\n",
    "\n",
    "# Flatten extracted features\n",
    "X_train_features_flat = X_train_features.reshape(X_train_features.shape[0], -1)\n",
    "X_valid_features_flat = X_valid_features.reshape(X_valid_features.shape[0], -1)\n",
    "\n",
    "# Normalize features\n",
    "max_val = X_train_features_flat.max()\n",
    "X_train_features_flat /= max_val\n",
    "X_valid_features_flat /= max_val\n",
    "\n",
    "# Define and Compile Model\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(X_train_features_flat.shape[1],)),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X_train_features_flat, y_train, epochs=100, validation_data=(X_valid_features_flat, y_valid))\n",
    "\n",
    "# Evaluate the Model\n",
    "predictions = model.predict(X_valid_features_flat)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_valid, axis=1)\n",
    "accuracy = np.mean(predicted_classes == true_classes)\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a47284-c85a-4e82-a473-89ecba248b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
